{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Libraries"
      ],
      "metadata": {
        "id": "VlBPe-RRnzK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-WEmTmboZwi",
        "outputId": "fb08fa8d-1fd0-4f5f-e781-998f0e35e638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.0.tar.gz (616 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.2/616.2 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (5.9.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch_geometric) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch_geometric) (1.1.1)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.0-py3-none-any.whl size=909897 sha256=58e38dec9bedfc57bdf197410042fd56cc4fc864b382770a5ea7ccd73014b13f\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/7d/6b/17150450b80b4a3656a84330e22709ccd8dc0f8f4773ba4133\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_sparse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EKERNQ6orPG",
        "outputId": "da268829-8edd-40a4-ab6c-a46d70a1dff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_sparse\n",
            "  Downloading torch_sparse-0.6.17.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch_sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch_sparse) (1.22.4)\n",
            "Building wheels for collected packages: torch_sparse\n",
            "  Building wheel for torch_sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_sparse: filename=torch_sparse-0.6.17-cp39-cp39-linux_x86_64.whl size=1082789 sha256=eac84f76ebe948917eabe3c4e5cb340dc2d4e31dd0396836eff0ccb9ab779319\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/43/54/bcb8acdd1109bd1e4c71106747af298d0315cdf3f090b2ae43\n",
            "Successfully built torch_sparse\n",
            "Installing collected packages: torch_sparse\n",
            "Successfully installed torch_sparse-0.6.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_scatter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E63iiHg9vXH_",
        "outputId": "52b56a4f-61d4-420c-84d1-85847f4c1dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_scatter\n",
            "  Downloading torch_scatter-2.1.1.tar.gz (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch_scatter\n",
            "  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_scatter: filename=torch_scatter-2.1.1-cp39-cp39-linux_x86_64.whl size=484407 sha256=b0d6fc624874e82c002fef86d4d65dcd6fe6134b866a2fecd2cf268f1f1e2ae6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/0c/18/11b4cf31446c5d460543b0fff930fcac3a3f8a785e5c73fb15\n",
            "Successfully built torch_scatter\n",
            "Installing collected packages: torch_scatter\n",
            "Successfully installed torch_scatter-2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISzej91WxYHk",
        "outputId": "d92c2382-fd86-46c7-b458-478e83eb610c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzdgIMnrMuMN",
        "outputId": "29a269d7-dc03-466a-a313-23c137ce6e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gnn\n",
            "  Downloading gnn-1.1.9-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: gnn\n",
            "Successfully installed gnn-1.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5MqXkLJnF90"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from pickle import FALSE\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.modules.activation import PReLU\n",
        "from torch_geometric.nn import GCNConv, GATConv,RGCNConv\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.inits import glorot, uniform\n",
        "from torch_geometric.utils import softmax\n",
        "import math\n",
        "\n",
        "from torch_sparse.tensor import to\n",
        "from utils import *\n",
        "from torch_sparse import SparseTensor, set_diag\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax, degree, to_undirected\n",
        "from torch.nn import Sequential, Linear, ReLU, Dropout\n",
        "from torch_scatter import scatter\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import delaxes\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import scipy.sparse as sparse"
      ],
      "metadata": {
        "id": "rmr-6rbnBlNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import times\n",
        "from tqdm.utils import SimpleTextIOWrapper\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# from gnn import RiskGNN\n",
        "from sklearn.metrics import accuracy_score as acc\n",
        "from sklearn.metrics import recall_score as rec\n",
        "from sklearn.metrics import precision_score as pre\n",
        "from sklearn.metrics import f1_score as f1\n",
        "from sklearn.metrics import roc_auc_score as roc\n",
        "\n",
        "import argparse"
      ],
      "metadata": {
        "id": "DNqg8-sTFahA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Functions**"
      ],
      "metadata": {
        "id": "DN5_gIK_yhSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#utils"
      ],
      "metadata": {
        "id": "64yX0SA6y-KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  set_random_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    # os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
        "    # os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.enabled = False\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.use_deterministic_algorithms(True)"
      ],
      "metadata": {
        "id": "zhUjVgItzBPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, n_hid, n_out):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.n_hid = n_hid\n",
        "        self.n_out = n_out\n",
        "        self.linear = nn.Linear(n_hid, n_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tx = self.linear(x)\n",
        "        return torch.log_softmax(tx.squeeze(), dim=-1)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}(n_hid={}, n_out={})'.format(\n",
        "            self.__class__.__name__, self.n_hid, self.n_out)"
      ],
      "metadata": {
        "id": "vOYnQJaNCFLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Graph"
      ],
      "metadata": {
        "id": "x0bhEAN1CQrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refer to https://github.com/iMoonLab/THU-HyperG/blob/master/hyperg/hyperg.py\n",
        "class HyperG:\n",
        "    def __init__(self, H, X=None, w=None):\n",
        "        \"\"\" Initial the incident matrix, node feature matrix and hyperedge weight vector of hypergraph\n",
        "        :param H: scipy coo_matrix of shape (n_nodes, n_edges)\n",
        "        :param X: numpy array of shape (n_nodes, n_features)\n",
        "        :param w: numpy array of shape (n_edges,)\n",
        "        \"\"\"\n",
        "        assert sparse.issparse(H)\n",
        "        assert H.ndim == 2\n",
        "\n",
        "        self._H = H\n",
        "        self._n_nodes = self._H.shape[0]\n",
        "        self._n_edges = self._H.shape[1]\n",
        "\n",
        "        if X is not None:\n",
        "            assert isinstance(X, np.ndarray) and X.ndim == 2\n",
        "            self._X = X\n",
        "        else:\n",
        "            self._X = None\n",
        "\n",
        "        if w is not None:\n",
        "            self.w = w.reshape(-1)\n",
        "            assert self.w.shape[0] == self._n_edges\n",
        "        else:\n",
        "            self.w = np.ones(self._n_edges)\n",
        "\n",
        "        self._DE = None\n",
        "        self._DV = None\n",
        "        self._INVDE = None\n",
        "        self._DV2 = None\n",
        "        self._THETA = None\n",
        "        self._L = None\n",
        "\n",
        "    def num_edges(self):\n",
        "        return self._n_edges\n",
        "\n",
        "    def num_nodes(self):\n",
        "        return self._n_nodes\n",
        "\n",
        "    def incident_matrix(self):\n",
        "        return self._H\n",
        "\n",
        "    def hyperedge_weights(self):\n",
        "        return self.w\n",
        "\n",
        "    def node_features(self):\n",
        "        return self._X\n",
        "\n",
        "    def node_degrees(self):\n",
        "        if self._DV is None:\n",
        "            H = self._H.tocsr()\n",
        "            dv = H.dot(self.w.reshape(-1, 1)).reshape(-1)\n",
        "            self._DV = sparse.diags(dv, shape=(self._n_nodes, self._n_nodes))\n",
        "        return self._DV\n",
        "\n",
        "    def edge_degrees(self):\n",
        "        if self._DE is None:\n",
        "            H = self._H.tocsr()\n",
        "            de = H.sum(axis=0).A.reshape(-1)\n",
        "            self._DE = sparse.diags(de, shape=(self._n_edges, self._n_edges))\n",
        "        return self._DE\n",
        "\n",
        "    def inv_edge_degrees(self):\n",
        "        if self._INVDE is None:\n",
        "            self.edge_degrees()\n",
        "            inv_de = np.power(self._DE.data.reshape(-1), -1.)\n",
        "            self._INVDE = sparse.diags(inv_de, shape=(self._n_edges, self._n_edges))\n",
        "        return self._INVDE\n",
        "\n",
        "    def inv_square_node_degrees(self):\n",
        "        if self._DV2 is None:\n",
        "            self.node_degrees()\n",
        "            dv2 = np.power(self._DV.data.reshape(-1)+1e-6, -0.5)\n",
        "            self._DV2 = sparse.diags(dv2, shape=(self._n_nodes, self._n_nodes))\n",
        "        return self._DV2\n",
        "\n",
        "    def theta_matrix(self):\n",
        "        if self._THETA is None:\n",
        "            self.inv_square_node_degrees()\n",
        "            self.inv_edge_degrees()\n",
        "\n",
        "            W = sparse.diags(self.w)\n",
        "            self._THETA = self._DV2.dot(self._H).dot(W).dot(self._INVDE).dot(self._H.T).dot(self._DV2)\n",
        "\n",
        "        return self._THETA\n",
        "\n",
        "    def laplacian(self):\n",
        "        if self._L is None:\n",
        "            self.theta_matrix()\n",
        "            self._L = sparse.eye(self._n_nodes) - self._THETA\n",
        "        return self._L\n",
        "\n",
        "    def update_hyedge_weights(self, w):\n",
        "        assert isinstance(w, (np.ndarray, list)), \\\n",
        "            \"The hyperedge array should be a numpy.ndarray or list\"\n",
        "\n",
        "        self.w = np.array(w).reshape(-1)\n",
        "        assert w.shape[0] == self._n_edges\n",
        "\n",
        "        self._DV = None\n",
        "        self._DV2 = None\n",
        "        self._THETA = None\n",
        "        self._L = None\n",
        "\n",
        "    def update_incident_matrix(self, H):\n",
        "        assert sparse.issparse(H)\n",
        "        assert H.ndim == 2\n",
        "        assert H.shape[0] == self._n_nodes\n",
        "        assert H.shape[1] == self._n_edges\n",
        "\n",
        "        # TODO: reset hyperedge weights?\n",
        "\n",
        "        self._H = H\n",
        "        self._DE = None\n",
        "        self._DV = None\n",
        "        self._INVDE = None\n",
        "        self._DV2 = None\n",
        "        self._THETA = None\n",
        "        self._L = None"
      ],
      "metadata": {
        "id": "LV_VugtcCK_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_log(message):\n",
        "    \"\"\"\n",
        "    :param message: str,\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    print(\"[{}] {}\".format(time.strftime(\"%Y-%m-%d %X\", time.localtime()), message))"
      ],
      "metadata": {
        "id": "_-7NrtTCCcR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_attribute_hg(n_nodes, attr_dict, X=None):\n",
        "    \"\"\"\n",
        "    :param attr_dict: dict, eg. {'attri_1': [node_idx_1, node_idx_1, ...], 'attri_2':[...]} (zero-based indexing)\n",
        "    :param n_nodes: int,\n",
        "    :param X: numpy array, shape = (n_samples, n_features) (optional)\n",
        "    :return: instance of HyperG\n",
        "    \"\"\"\n",
        "\n",
        "    if X is not None:\n",
        "        assert n_nodes == X.shape[0]\n",
        "\n",
        "    n_edges = len(attr_dict)\n",
        "    node_idx = []\n",
        "    edge_idx = []\n",
        "\n",
        "    for idx, attr in enumerate(attr_dict):\n",
        "        nodes = sorted(attr_dict[attr])\n",
        "        node_idx.extend(nodes)\n",
        "        edge_idx.extend([idx] * len(nodes))\n",
        "\n",
        "    node_idx = np.asarray(node_idx)\n",
        "    edge_idx = np.asarray(edge_idx)\n",
        "    values = np.ones(node_idx.shape[0])\n",
        "\n",
        "    H = sparse.coo_matrix((values, (node_idx, edge_idx)), shape=(n_nodes, n_edges))\n",
        "    return HyperG(H, X=X)"
      ],
      "metadata": {
        "id": "vcDRKliACgHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scipy_sparse_mat_to_torch_sparse_tensor(sparse_mx):\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)"
      ],
      "metadata": {
        "id": "FfwEZ09nC28Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#refer to https://github.com/alge24/DyGNN/blob/b161555a5df69bd3fa9cc3ae5d4f5cd65ebe3a0f/decayer.py\n",
        "class Decayer(nn.Module):\n",
        "    def __init__(self, w1=0.01,w2=0.1, decay_method='rev'):\n",
        "    # def __init__(self, w1=100,w2=200, decay_method='rev'):\n",
        "        super(Decayer,self).__init__()\n",
        "        self.decay_method = decay_method\n",
        "        self.w1 = w1\n",
        "        self.w2=w2\n",
        "\n",
        "    def exponetial_decay(self, w, delta_t):\n",
        "        return torch.exp(-w*delta_t)\n",
        "    def log_decay(self, w, delta_t):\n",
        "        return 1/torch.log(2.7183 + w*delta_t)\n",
        "    def rev_decay(self, w, delta_t):\n",
        "        return 1/(1 + w*delta_t)\n",
        "\n",
        "    def forward(self,delta_t):\n",
        "        seq=torch.zeros_like(delta_t)\n",
        "\n",
        "        idx1=(delta_t<=24)\n",
        "        idx2=(delta_t>24)\n",
        "\n",
        "        # # print(delta_t)\n",
        "        if self.decay_method == 'exp':\n",
        "            seq[idx1]=self.exponetial_decay(self.w1,delta_t[idx1])\n",
        "            seq[idx2]=self.exponetial_decay(self.w2,delta_t[idx2])\n",
        "        elif self.decay_method == 'log':\n",
        "            seq[idx1]=self.log_decay(self.w1,delta_t[idx1])\n",
        "            seq[idx2]=self.log_decay(self.w2,delta_t[idx2])\n",
        "        elif self.decay_method == 'rev':\n",
        "            seq[idx1]=self.rev_decay(self.w1,delta_t[idx1])\n",
        "            seq[idx2]=self.rev_decay(self.w2,delta_t[idx2])\n",
        "\n",
        "        else:\n",
        "            seq[idx1]=self.exponetial_decay(delta_t[idx1])\n",
        "            seq[idx2]=self.exponetial_decay(delta_t[idx2])\n",
        "        # print(seq,\"----\")\n",
        "\n",
        "        return seq"
      ],
      "metadata": {
        "id": "JF0Y02MuDD-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initializae_company_info(risk_data,company_attr,company_num,cause_type_num,court_type,category,idx=None):\n",
        "    if idx:\n",
        "        idx_dict={index:ser for ser,index in enumerate(idx)}\n",
        "    company_risk=np.zeros((company_num,cause_type_num+court_type+category+1))\n",
        "    for index in risk_data:\n",
        "        risk_info=risk_data[index]\n",
        "        cause_info=[0 for i in range(cause_type_num)]\n",
        "        court_info=[0 for i in range(court_type)]\n",
        "        res_info=[0 for i in range(category)]\n",
        "        time_info=[]\n",
        "        for i in range(len(risk_info)):\n",
        "            justify=risk_info[i]\n",
        "            cause=justify[0]\n",
        "            court=justify[1]\n",
        "            res=justify[2]\n",
        "            time=justify[3]\n",
        "            cause_info[cause]+=1\n",
        "            court_info[court]+=1\n",
        "            res_info[res]+=1\n",
        "            time_info+=[time]\n",
        "        time_ave=[np.average(time_info)]\n",
        "        if idx:\n",
        "            company_risk[idx_dict[index]]=np.concatenate((cause_info,court_info,res_info,time_ave),axis=0)\n",
        "        else:\n",
        "            company_risk[index]=np.concatenate((cause_info,court_info,res_info,time_ave),axis=0)\n",
        "    company_attr=np.array(company_attr)\n",
        "    company_info=np.concatenate((company_attr,company_risk),axis=1)\n",
        "    return company_info"
      ],
      "metadata": {
        "id": "TQikp5fmDOXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Heterogeneous Graphs"
      ],
      "metadata": {
        "id": "vyS0lKeZp96_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HeteGNN(MessagePassing):\n",
        "    def __init__(self, input_dim,output_dim,rel_num,negative_slope=0.2,num_company_rel=7,num_person_rel=3,\n",
        "    aggr = \"add\", flow= \"source_to_target\", node_dim = -2):\n",
        "        super(HeteGNN,self).__init__(aggr=aggr, flow=flow, node_dim=node_dim)\n",
        "        self.input_dim=input_dim\n",
        "        self.output_dim=output_dim\n",
        "        self.rel_num=rel_num\n",
        "        self.negative_slope=negative_slope\n",
        "\n",
        "        self.proj_com=nn.Linear(input_dim,output_dim,bias=False)\n",
        "        self.proj_per=nn.Linear(input_dim,output_dim,bias=False)\n",
        "\n",
        "        self.ck_linears   = nn.ModuleList()\n",
        "        self.cq_linears   = nn.ModuleList()\n",
        "\n",
        "        for t in range(rel_num):\n",
        "            self.ck_linears.append(nn.Linear(output_dim,   output_dim))\n",
        "            self.cq_linears.append(nn.Linear(output_dim,   output_dim))\n",
        "\n",
        "        self.cv_linear=nn.Linear(output_dim,   output_dim)\n",
        "        self.crelation_pri   = nn.Parameter(torch.ones(rel_num))\n",
        "\n",
        "        self.rel_wi=nn.ModuleList()\n",
        "        for i in range(rel_num):\n",
        "            if i in [6,7,8,9]:\n",
        "                self.rel_wi.append(nn.Linear(output_dim,output_dim,bias=False))\n",
        "            else:\n",
        "                self.rel_wi.append(nn.Linear(output_dim*2,output_dim,bias=False))\n",
        "\n",
        "\n",
        "        self.skip = nn.Parameter(torch.ones(1))\n",
        "        self.bn=nn.BatchNorm1d(output_dim)\n",
        "\n",
        "    def forward(self,company_emb,person_emb,edge_index,edge_type,edge_weight,company_num,person_num):\n",
        "        company_emb=self.proj_com(company_emb)\n",
        "        person_emb=self.proj_per(person_emb)\n",
        "        emb=torch.cat((company_emb,person_emb),dim=0)\n",
        "        emb=self.bn(emb)\n",
        "        edge_index= torch.LongTensor(edge_index).transpose(0,1)\n",
        "\n",
        "        edge_type=torch.LongTensor(edge_type)\n",
        "        edge_weight=torch.FloatTensor(edge_weight).unsqueeze(1)\n",
        "\n",
        "        rs_list=[]\n",
        "        rel_type=[]\n",
        "\n",
        "        for i in range(self.rel_num):\n",
        "            mask = (edge_type == i)\n",
        "            sub_edge_index = edge_index[:, mask]\n",
        "            sub_edge_weight=edge_weight[mask]\n",
        "            if mask.sum() !=0:\n",
        "                rs=F.leaky_relu((self.propagate(sub_edge_index, x=emb,edge_weight=sub_edge_weight,edge_type=i)),self.negative_slope)\n",
        "                rs_list+=[rs]\n",
        "                rel_type+=[i]\n",
        "        com_att=[]\n",
        "\n",
        "        for ser,i in enumerate(rel_type):\n",
        "\n",
        "            rel_emb=rs_list[ser]\n",
        "            q_mat = self.cq_linears[i](emb)\n",
        "            k_mat = self.ck_linears[i](rel_emb)\n",
        "            res_att = ((q_mat * k_mat).sum(dim=-1) * self.crelation_pri[i] / math.sqrt(self.output_dim)).unsqueeze(1)\n",
        "\n",
        "            com_att+=[res_att]\n",
        "\n",
        "        com_attscore=torch.cat(com_att,dim=1)\n",
        "        com_attscore=F.softmax(com_attscore,dim=1)\n",
        "        res=0\n",
        "        for i in range(len(com_att)):\n",
        "            res+= com_attscore[:,i].unsqueeze(1) * self.cv_linear(rs_list[i])\n",
        "        alpha=torch.sigmoid(self.skip)\n",
        "        res=(res+alpha*F.gelu(emb))\n",
        "        res_c,res_p=res[:company_num],res[company_num:]\n",
        "\n",
        "        return res_c,res_p\n",
        "\n",
        "    def message(self,edge_index, x_i,x_j, edge_weight, edge_type):\n",
        "        if torch.sum(edge_weight)!=edge_index.shape[1]:\n",
        "            x_j=self.rel_wi[edge_type](x_j)\n",
        "            edge_weight=softmax(edge_weight,edge_index[1])\n",
        "            rs=x_j*edge_weight\n",
        "        else:\n",
        "            node_f = torch.cat((x_i, x_j), 1)                                       #nx2d\n",
        "            temp = self.rel_wi[edge_type](node_f).to(x_i.device)      #nx1\n",
        "\n",
        "            alpha=softmax(temp,edge_index[1])\n",
        "\n",
        "            rs=x_j*alpha\n",
        "        return rs\n",
        "\n",
        "    def update(self, inputs):\n",
        "        return super().update(inputs)"
      ],
      "metadata": {
        "id": "HWKs3uTjn43L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyper GNN"
      ],
      "metadata": {
        "id": "iGi6VARqpZCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HyperGNN(nn.Module):\n",
        "    def __init__(self,input_dim,output_dim,hyper_edge_num=3,num_layer=1,negative_slope=0.2):\n",
        "        super(HyperGNN,self).__init__()\n",
        "        self.negative_slope=negative_slope\n",
        "        \n",
        "        self.proj=nn.Linear(input_dim,output_dim,bias=False)\n",
        "       \n",
        "        self.alpha=nn.Parameter(torch.ones(hyper_edge_num,1))\n",
        "        \n",
        "        glorot(self.alpha)\n",
        "\n",
        "    def forward(self,company_emb,hyp_graph):\n",
        "        outlist=[]\n",
        "        for i in range(len(hyp_graph)):\n",
        "            laplacian=scipy_sparse_mat_to_torch_sparse_tensor(hyp_graph[i].laplacian())\n",
        "            rs= laplacian@self.proj(company_emb)\n",
        "            outlist+=[rs]\n",
        "           \n",
        "        res=0\n",
        "       \n",
        "        alpha=torch.sigmoid(self.alpha)\n",
        "        print(\"alpha = \", alpha)\n",
        "        print(\"Outlist len = \", len(outlist))\n",
        "        print(\"Outlist 0 len = \", len(outlist[0]))\n",
        "        print(\"Outlist 0 1 len = \", len(outlist[0][1]))\n",
        "\n",
        "        print(\"Outlist 1 len = \", len(outlist[1]))\n",
        "        print(\"Outlist 2 len = \", len(outlist[2]))\n",
        "\n",
        "        for i in range(len(outlist)):\n",
        "            #print(\"RES \", i, \"= \", res)\n",
        "            res+=outlist[i]*alpha[i]\n",
        "            \n",
        "        print(\"res len = \", len(res))\n",
        "        print(\"res 0 len =\", len(res[0]))\n",
        "        print(\"res 5 len =\", len(res[5]))\n",
        "        print(\"res 10 len =\", len(res[10]))\n",
        "        print(\"res 0 = \", res[0])\n",
        "        return res"
      ],
      "metadata": {
        "id": "-vJ-g8-Uqe8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Risk Analysis"
      ],
      "metadata": {
        "id": "aLA-NLOdwV41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RiskInfo(nn.Module):\n",
        "    def __init__(self,input_dim,company_num,cause_type_num,court_type_num,res_num,time_label_num):\n",
        "        super(RiskInfo,self).__init__()\n",
        "        self.input_dim=input_dim\n",
        "        self.company_num=company_num\n",
        "        self.time_lable_num=2\n",
        "\n",
        "\n",
        "        self.ca_emb=nn.Embedding(cause_type_num,12)\n",
        "        self.court_emb=nn.Embedding(court_type_num,4)\n",
        "        self.cate_emb=nn.Embedding(res_num,4)\n",
        "        self.lstm_hidden=20\n",
        "\n",
        "        self.proj=nn.Linear(20,20,bias=False)\n",
        "\n",
        "\n",
        "        self.time_decay=Decayer()\n",
        "\n",
        "\n",
        "    def forward(self,risk_data):\n",
        "\n",
        "        com_emb=torch.zeros((self.company_num,self.lstm_hidden))\n",
        "\n",
        "        for index in risk_data:\n",
        "            cause=self.ca_emb(torch.LongTensor(risk_data[index])[:,0]) \n",
        "            court=self.court_emb(torch.LongTensor(risk_data[index])[:,1])\n",
        "            cate=self.cate_emb(torch.LongTensor(risk_data[index])[:,2])\n",
        "            risk=torch.cat((cause,court,cate),dim=1)\n",
        "\n",
        "            time_interval=torch.FloatTensor(risk_data[index])[:,3]\n",
        "\n",
        "            time_interval=self.time_decay(time_interval).unsqueeze(1)\n",
        "\n",
        "            risk=self.proj(time_interval*risk)\n",
        "\n",
        "            com_emb[index]=risk.sum(0)\n",
        "        return com_emb"
      ],
      "metadata": {
        "id": "4K0FBsayweNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Risk GNN"
      ],
      "metadata": {
        "id": "nwX1mSHLwoVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RiskGNN(nn.Module):\n",
        "    def __init__(self,input_dim,output_dim,\n",
        "    company_num,person_num,rel_num,cause_type_num,\n",
        "     device,com_initial_emb,person_initial_emb,\n",
        "     court_type_num=4,category_num=4,time_label_num=5,num_heads=1,dropout=0.2,norm=True,\n",
        "     ):\n",
        "        super(RiskGNN,self).__init__()\n",
        "        self.input_dim=input_dim\n",
        "        self.output_dim=output_dim\n",
        "        self.company_num=company_num\n",
        "        self.person_num=person_num\n",
        "        self.rel_num=rel_num\n",
        "        self.cause_type=cause_type_num\n",
        "        self.device=device\n",
        "        self.court_type=court_type_num\n",
        "        self.category_=category_num\n",
        "        self.num_heads=num_heads\n",
        "        self.dropout=dropout\n",
        "        self.norm=norm\n",
        "        self.company_emb=torch.FloatTensor(com_initial_emb)\n",
        "        self.person_emb=torch.FloatTensor(person_initial_emb)\n",
        "\n",
        "        self.riskinfo=RiskInfo(input_dim,company_num,cause_type_num,court_type_num,category_num,time_label_num=time_label_num)\n",
        "        self.hypergnn=HyperGNN(input_dim,output_dim,num_layer=1)\n",
        "        self.hetegnn=nn.ModuleList()\n",
        "        for i in range(5):\n",
        "            if i==0:\n",
        "                self.hetegnn.append(HeteGNN(input_dim,output_dim,rel_num))\n",
        "            else:\n",
        "                self.hetegnn.append(HeteGNN(output_dim,output_dim,rel_num))\n",
        "\n",
        "        self.company_proj=nn.Linear(32,input_dim,bias=False)\n",
        "        self.person_proj=nn.Linear(32,input_dim,bias=False)\n",
        "\n",
        "        self.risk_proj=nn.Linear(input_dim+23,input_dim,bias=False)\n",
        "        self.info_proj=nn.Linear(output_dim,output_dim,bias=False)\n",
        "\n",
        "        self.final_proj=nn.Sequential(nn.Linear(input_dim,output_dim,bias=False),nn.ReLU(),nn.Linear(output_dim,output_dim,bias=False))\n",
        "        self.alpha=torch.ones((1))\n",
        "\n",
        "\n",
        "    # risk data: dict-->{company_index:[[cause type, court type, category, time(months),time_label],...] }\n",
        "    # company attribute information: np.array()-->[[register_captial, paid_captial, set up time(months)]]\n",
        "    # graph: edge index:[sour,tar].T -->2xN; edge type: [,,...,] -->N; edge weight:[,,...,]-->N\n",
        "    # hyper graph: dict:{industry:{ind1:[...],ind2:[...],...},area:{area1:[...],area2:[...],...},qualify:{qua1:[...],qua2:[...],...}}\n",
        "    def forward(self,risk_data,company_attr,hete_graph,hyp_graph,idx,x):\n",
        "        company_emb=self.company_proj(self.company_emb)\n",
        "        person_emb=self.person_proj(self.person_emb)\n",
        "        company_basic_info=torch.zeros((self.company_num,len(company_attr[0])))\n",
        "       \n",
        "        company_basic_info[idx]=torch.Tensor(company_attr)\n",
        "        \n",
        "        company_emb=torch.cat((company_emb,company_basic_info),dim=1)\n",
        "        risk_info=self.riskinfo(risk_data)\n",
        "        company_emb_info=self.risk_proj(torch.cat((company_emb,risk_info),dim=1))\n",
        "\n",
        "        company_emb_hyper=self.hypergnn(company_emb_info,hyp_graph)\n",
        "\n",
        "        edge_index,edge_type,edge_weight=hete_graph\n",
        "\n",
        "        for i in range(5):\n",
        "            if i==0:\n",
        "                company_emb_hete,person_emb=self.hetegnn[i](company_emb_info,person_emb,edge_index,edge_type,edge_weight,self.company_num,self.person_num)\n",
        "            else:\n",
        "                company_emb_hete,person_emb=self.hetegnn[i](company_emb_hete,person_emb,edge_index,edge_type,edge_weight,self.company_num,self.person_num)\n",
        "        company_emb_final=self.info_proj(company_emb_hyper+company_emb_hete)\n",
        "\n",
        "        alpha=torch.sigmoid(self.alpha)\n",
        "        company_emb_final=alpha*F.gelu(company_emb_final)+(1-alpha)*self.final_proj(company_emb_info)\n",
        "\n",
        "        return company_emb_final[idx]"
      ],
      "metadata": {
        "id": "azOCGz6swh4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dfBG0M--xi9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training"
      ],
      "metadata": {
        "id": "b7bXTfabEAND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser(description='Training GNN')"
      ],
      "metadata": {
        "id": "Pyxa4eRyEDwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset arguments"
      ],
      "metadata": {
        "id": "Dqz_4xbcVSl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser.add_argument('--data_dir', type=str, default='./data', help='The address of preprocessed graph.')\n",
        "parser.add_argument('--model_dir', type=str, default='.\\model_save', help='The address for storing the models and optimization results.')\n",
        "parser.add_argument('--cuda', type=int, default=0, help='Avaiable GPU ID')"
      ],
      "metadata": {
        "id": "0ePr89z4VPi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ed2871-9cc6-462b-d654-cf7437436d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--cuda'], dest='cuda', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, required=False, help='Avaiable GPU ID', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model arguments"
      ],
      "metadata": {
        "id": "351PpEtDWGBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser.add_argument('--conv_name', type=str, default='riskgnn', choices=['riskgnn'], help='The name of GNN filter.')\n",
        "parser.add_argument('--input_dim', type=int, default=16, help='Number of input dimension')\n",
        "parser.add_argument('--output_dim', type=int, default=12, help='Number of output dimension')\n",
        "parser.add_argument('--n_heads', type=int, default=1, help='Number of attention head')\n",
        "parser.add_argument('--n_layers', type=int, default=1, help='Number of HeteGAT layers')\n",
        "parser.add_argument('--dropout', type=float, default=0.2, help='Dropout ratio')"
      ],
      "metadata": {
        "id": "pryDtfSXVlbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c751e95-231d-4971-f3f5-ebfdef53fac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--dropout'], dest='dropout', nargs=None, const=None, default=0.2, type=<class 'float'>, choices=None, required=False, help='Dropout ratio', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization arguments"
      ],
      "metadata": {
        "id": "jHX18b_uWLS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser.add_argument('--optimizer', type=str, default='adam', choices=['adamw', 'adam', 'sgd', 'adagrad'], help='optimizer to use.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhvXo1qh7iJL",
        "outputId": "d06822fa-0fa7-4006-bba8-b45666665d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--optimizer'], dest='optimizer', nargs=None, const=None, default='adam', type=<class 'str'>, choices=['adamw', 'adam', 'sgd', 'adagrad'], required=False, help='optimizer to use.', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser.add_argument('--n_epoch', type=int, default=10, help='Number of epoch to run')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td9xh9Nk7kz4",
        "outputId": "59e25c97-51d1-43a8-f8c1-7ca235ec4790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--n_epoch'], dest='n_epoch', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, required=False, help='Number of epoch to run', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser.add_argument('--clip', type=float, default=0.25, help='Gradient Norm Clipping')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBF_FlY27oeg",
        "outputId": "cf33ae3a-8b34-4eb9-ef2f-24d73181f336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--clip'], dest='clip', nargs=None, const=None, default=0.25, type=<class 'float'>, choices=None, required=False, help='Gradient Norm Clipping', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser.add_argument('--weight_decay', type=float, default=1e-4, help='weight decay of adamw ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdQNvCOx7qGW",
        "outputId": "e18a8e9b-3f5d-4521-9527-b57ce34a1899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--weight_decay'], dest='weight_decay', nargs=None, const=None, default=0.0001, type=<class 'float'>, choices=None, required=False, help='weight decay of adamw ', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#args = parser.parse_args()"
      ],
      "metadata": {
        "id": "2xTCEUmnWMmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args, unknown = parser.parse_known_args()"
      ],
      "metadata": {
        "id": "Ln4T3vadJxrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cpu\")\n",
        "set_random_seed(14)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "k8sFO5dcWbh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_company_num=3976\n",
        "person_num=2405\n",
        "court_type=4\n",
        "category=4\n",
        "time_label_num=5\n",
        "\n",
        "train_company_num=2816\n",
        "valid_company_num=721\n",
        "test_company_num=491\n",
        "\n",
        "rel_num=12\n",
        "cause_type_num=11"
      ],
      "metadata": {
        "id": "8iSz22fXWgSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "v_b3S9ItXFPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEnUl60nK0-s",
        "outputId": "abe5f2ed-db52-415e-d50a-a3fe9cdd33f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=pd.read_pickle('/content/drive/MyDrive/GNN/train_data.pkl')\n",
        "valid_data=pd.read_pickle('/content/drive/MyDrive/GNN/validate_data.pkl')\n",
        "test_data=pd.read_pickle('/content/drive/MyDrive/GNN/test_data.pkl')\n",
        "split_data_idx=pd.read_pickle('/content/drive/MyDrive/GNN/split_data_idx.pkl')\n",
        "com_initial_emb,person_initial_emb=pd.read_pickle('/content/drive/MyDrive/GNN/meta_emb.pkl')"
      ],
      "metadata": {
        "id": "2QPEJp6yW2Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_risk_data,train_company_attr,train_hete_graph,train_hyp_graph,train_label=train_data\n",
        "valid_risk_data,valid_company_attr,valid_hete_graph,valid_hyp_graph,valid_label=valid_data\n",
        "test_risk_data,test_company_attr,test_hete_graph,test_hyp_graph,test_label=test_data\n",
        "train_idx,valid_idx,test_idx=split_data_idx"
      ],
      "metadata": {
        "id": "ld4Xj-0DXIHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=initializae_company_info(train_risk_data,train_company_attr,train_company_num,cause_type_num,court_type,category,train_idx)\n",
        "x_valid=initializae_company_info(valid_risk_data,valid_company_attr,valid_company_num,cause_type_num,court_type,category,valid_idx)\n",
        "x_test=initializae_company_info(test_risk_data,test_company_attr,test_company_num,cause_type_num,court_type,category,test_idx)"
      ],
      "metadata": {
        "id": "3ioVgRnoXMGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph Neural Network"
      ],
      "metadata": {
        "id": "PNYYIf6DIGLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gnn=RiskGNN(args.input_dim,args.output_dim, total_company_num,person_num,rel_num, cause_type_num, device,com_initial_emb,person_initial_emb, court_type,category,time_label_num, num_heads=1,dropout=0.2,norm=True)"
      ],
      "metadata": {
        "id": "lF5P1b6pIFnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Classifier(args.output_dim, 2).to(device)\n",
        "model = nn.Sequential(gnn, classifier)"
      ],
      "metadata": {
        "id": "iDTvQB_dITNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if args.optimizer == 'adamw':\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),weight_decay=args.weight_decay)\n",
        "elif args.optimizer == 'adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
        "elif args.optimizer == 'sgd':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "elif args.optimizer == 'adagrad':\n",
        "    optimizer = torch.optim.Adagrad(model.parameters())"
      ],
      "metadata": {
        "id": "1Mtr8rgKIgoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 20, eta_min=1e-6)"
      ],
      "metadata": {
        "id": "3_v_8tttIkY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "['industry', 'area', 'qualify']\n",
        "train_hyp=[]\n",
        "for i in ['industry', 'area', 'qualify']:\n",
        "    train_hyp+=[gen_attribute_hg(total_company_num, train_hyp_graph[i], X=None)]\n",
        "valid_hyp=[]\n",
        "for i in ['industry', 'area', 'qualify']:\n",
        "    valid_hyp+=[gen_attribute_hg(total_company_num, valid_hyp_graph[i], X=None)]\n",
        "test_hyp=[]\n",
        "for i in ['industry', 'area', 'qualify']:\n",
        "    test_hyp+=[gen_attribute_hg(total_company_num, test_hyp_graph[i], X=None)]"
      ],
      "metadata": {
        "id": "ZE36OOc7IodU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    best_model = torch.load('./model_save/%s.pkl'%(args.conv_name))\n",
        "    best_model.eval()\n",
        "    gnn, classifier = best_model\n",
        "    with torch.no_grad():\n",
        "        company_emb=gnn.forward(test_risk_data,test_company_attr,test_hete_graph,test_hyp,test_idx,x_test)\n",
        "\n",
        "        res = classifier.forward(company_emb)\n",
        "\n",
        "        pred=res.argmax(dim=1)\n",
        "        ac=acc(test_label,pred)\n",
        "        pr=pre(test_label,pred)\n",
        "        re=rec(test_label,pred)\n",
        "        f=f1(test_label,pred)\n",
        "        rc=roc(test_label,res[:,1])\n",
        "\n",
        "        print('Best Test Acc: %.4f Best Test Pre: %.4f Best Test Recall: %.4f Best Test F1: %.4f Best Test ROC: %.4f' % (ac,pr,re,f,rc))\n",
        "        print(sum(pred))"
      ],
      "metadata": {
        "id": "atBbyrMdI1vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc=0\n",
        "best_f1=0"
      ],
      "metadata": {
        "id": "ChR7VeR1I5YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in np.arange(args.n_epoch):\n",
        "\n",
        "    st=time.time()\n",
        "\n",
        "    '''\n",
        "        Train \n",
        "    '''\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    # torch.cuda.empty_cache()\n",
        "    company_emb=gnn.forward(train_risk_data,train_company_attr,train_hete_graph,train_hyp,train_idx,x_train)\n",
        "\n",
        "    \n",
        "    res = classifier.forward(company_emb)\n",
        "\n",
        "    loss = criterion(res, torch.LongTensor(train_label))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    train_losses += [loss.cpu().detach().tolist()]\n",
        "    # train_step += 1\n",
        "    scheduler.step()\n",
        "    del res, loss\n",
        "\n",
        "    '''\n",
        "        Valid \n",
        "    '''\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        company_emb=gnn.forward(valid_risk_data,valid_company_attr,valid_hete_graph,valid_hyp,valid_idx,x_valid)\n",
        "\n",
        "        res = classifier.forward(company_emb)\n",
        "        loss = criterion(res,torch.LongTensor(valid_label) )\n",
        "\n",
        "        pred=res.argmax(dim=1)\n",
        "        ac=acc(valid_label,pred)\n",
        "        pr=pre(valid_label,pred)\n",
        "        re=rec(valid_label,pred)\n",
        "        f=f1(valid_label,pred)\n",
        "        rc=roc(valid_label,res[:,1])\n",
        "\n",
        "        if ac > best_acc and f>best_f1:\n",
        "            best_acc = ac\n",
        "            best_f1=f\n",
        "            torch.save(model, '/content/drive/MyDrive/GNN/%s.pkl'%(args.conv_name))  # args.conv_name = riskgnn\n",
        "\n",
        "            print('UPDATE!!!')\n",
        "\n",
        "\n",
        "        et = time.time()\n",
        "        print((\"Epoch: %d (%.1fs)  LR: %.5f Train Loss: %.2f  Valid Loss: %.2f  Valid Acc: %.4f Valid Pre: %.4f  Valid Recall: %.4f Valid F1: %.4f  Valid Roc: %.4f\"  ) % \\\n",
        "              (epoch, (et - st), optimizer.param_groups[0]['lr'], np.average(train_losses), \\\n",
        "               loss.cpu().detach().tolist(), ac,pr,re,f,rc))\n",
        "\n",
        "        del res, loss\n",
        "\n",
        "        if epoch+1==args.n_epoch:\n",
        "            company_emb=gnn.forward(test_risk_data,test_company_attr,test_hete_graph,test_hyp,test_idx,x_test)\n",
        "\n",
        "            res = classifier.forward(company_emb)\n",
        "\n",
        "            pred=res.argmax(dim=1)\n",
        "            ac=acc(test_label,pred)\n",
        "            pr=pre(test_label,pred)\n",
        "            re=rec(test_label,pred)\n",
        "            f=f1(test_label,pred)\n",
        "            rc=roc(test_label,res[:,1])\n",
        "            \n",
        "            print('Last Test Acc: %.4f Last Test Pre: %.4f Last Test Recall: %.4f Last Test F1: %.4f Last Test ROC: %.4f' % (ac,pr,re,f,rc))"
      ],
      "metadata": {
        "id": "iKXYcZ7hI86u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81181d4e-1476-40a2-931d-17365dde6d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha =  tensor([[0.2254],\n",
            "        [0.3951],\n",
            "        [0.5730]], grad_fn=<SigmoidBackward0>)\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([-359.7084, -980.8617,  185.2680,  424.3913, -132.3065,  693.8123,\n",
            "        -372.6189,  128.8235, -152.4756, -817.1254,  710.8715,  -49.8491],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "alpha =  tensor([[0.2237],\n",
            "        [0.3930],\n",
            "        [0.5712]])\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ 0.0280,  0.0434,  0.0392, -0.0422,  0.0026, -0.0114,  0.0458,  0.0021,\n",
            "        -0.0359,  0.0322,  0.0212,  0.0420])\n",
            "UPDATE!!!\n",
            "Epoch: 0 (1.7s)  LR: 0.00976 Train Loss: 4.80  Valid Loss: 8.87  Valid Acc: 0.5479 Valid Pre: 0.5260  Valid Recall: 0.7994 Valid F1: 0.6345  Valid Roc: 0.5357\n",
            "alpha =  tensor([[0.2237],\n",
            "        [0.3930],\n",
            "        [0.5712]], grad_fn=<SigmoidBackward0>)\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ -213.1802, -1052.3511,   254.5863,   353.8167,  -168.3453,   830.2751,\n",
            "         -299.2047,    24.4586,  -426.2883,  -538.5536,   921.3606,   -60.1472],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "alpha =  tensor([[0.2223],\n",
            "        [0.3909],\n",
            "        [0.5692]])\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ 0.0285,  0.0410,  0.0364, -0.0422, -0.0018, -0.0100,  0.0471,  0.0042,\n",
            "        -0.0430,  0.0321,  0.0176,  0.0412])\n",
            "UPDATE!!!\n",
            "Epoch: 1 (1.8s)  LR: 0.00946 Train Loss: 15.53  Valid Loss: 7.67  Valid Acc: 0.5534 Valid Pre: 0.5301  Valid Recall: 0.7966 Valid F1: 0.6366  Valid Roc: 0.5405\n",
            "alpha =  tensor([[0.2223],\n",
            "        [0.3909],\n",
            "        [0.5692]], grad_fn=<SigmoidBackward0>)\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([-216.2710, -976.7484,  281.0766,  273.2182,  -45.9044,  804.2078,\n",
            "        -239.3832,  -43.5420, -423.5134, -418.5705, 1008.3591,  -27.7157],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "alpha =  tensor([[0.2209],\n",
            "        [0.3888],\n",
            "        [0.5670]])\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ 0.0279,  0.0381,  0.0338, -0.0448, -0.0072, -0.0064,  0.0483,  0.0061,\n",
            "        -0.0535,  0.0326,  0.0135,  0.0416])\n",
            "Epoch: 2 (1.7s)  LR: 0.00905 Train Loss: 12.50  Valid Loss: 5.45  Valid Acc: 0.5146 Valid Pre: 0.5667  Valid Recall: 0.0480 Valid F1: 0.0885  Valid Roc: 0.6371\n",
            "alpha =  tensor([[0.2209],\n",
            "        [0.3888],\n",
            "        [0.5670]], grad_fn=<SigmoidBackward0>)\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([-268.8665, -853.1870,  301.7798,  194.1968,  122.1191,  723.2589,\n",
            "        -184.4022,  -96.7291, -306.1732, -383.5777, 1048.7684,   30.1015],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "alpha =  tensor([[0.2195],\n",
            "        [0.3868],\n",
            "        [0.5650]])\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ 0.0312,  0.0378,  0.0330, -0.0419, -0.0085, -0.0085,  0.0503,  0.0068,\n",
            "        -0.0534,  0.0308,  0.0130,  0.0412])\n",
            "Epoch: 3 (1.8s)  LR: 0.00854 Train Loss: 7.81  Valid Loss: 4.67  Valid Acc: 0.5187 Valid Pre: 0.5778  Valid Recall: 0.0734 Valid F1: 0.1303  Valid Roc: 0.6209\n",
            "alpha =  tensor([[0.2195],\n",
            "        [0.3868],\n",
            "        [0.5650]], grad_fn=<SigmoidBackward0>)\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([-231.8066, -739.1606,  329.9385,  147.8910,  177.3588,  636.0991,\n",
            "         -95.1032, -143.9649, -299.5442, -367.1097, 1038.6283,   95.9588],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "alpha =  tensor([[0.2182],\n",
            "        [0.3848],\n",
            "        [0.5629]])\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ 0.0354,  0.0402,  0.0332, -0.0364, -0.0065, -0.0131,  0.0524,  0.0063,\n",
            "        -0.0472,  0.0276,  0.0145,  0.0411])\n",
            "Epoch: 4 (2.7s)  LR: 0.00794 Train Loss: 6.80  Valid Loss: 3.29  Valid Acc: 0.5465 Valid Pre: 0.5423  Valid Recall: 0.4887 Valid F1: 0.5141  Valid Roc: 0.5700\n",
            "alpha =  tensor([[0.2182],\n",
            "        [0.3848],\n",
            "        [0.5629]], grad_fn=<SigmoidBackward0>)\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([-154.3654, -641.7958,  358.0580,  117.1801,  170.9077,  557.4429,\n",
            "           8.1304, -192.3134, -350.4828, -362.2031, 1000.1756,  163.0388],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "alpha =  tensor([[0.2170],\n",
            "        [0.3831],\n",
            "        [0.5611]])\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ 0.0390,  0.0419,  0.0334, -0.0320, -0.0051, -0.0160,  0.0543,  0.0056,\n",
            "        -0.0423,  0.0254,  0.0159,  0.0413])\n",
            "Epoch: 5 (2.2s)  LR: 0.00727 Train Loss: 4.27  Valid Loss: 2.70  Valid Acc: 0.5395 Valid Pre: 0.5753  Valid Recall: 0.2373 Valid F1: 0.3360  Valid Roc: 0.6070\n",
            "alpha =  tensor([[0.2170],\n",
            "        [0.3831],\n",
            "        [0.5611]], grad_fn=<SigmoidBackward0>)\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([-102.9707, -520.3360,  395.6581,  109.2471,  208.9504,  447.5310,\n",
            "          96.7706, -214.6384, -339.9642, -384.8539,  976.1546,  237.4020],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "alpha =  tensor([[0.2160],\n",
            "        [0.3815],\n",
            "        [0.5594]])\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ 0.0425,  0.0457,  0.0341, -0.0277, -0.0018, -0.0196,  0.0558,  0.0037,\n",
            "        -0.0350,  0.0227,  0.0185,  0.0419])\n",
            "Epoch: 6 (1.6s)  LR: 0.00655 Train Loss: 4.05  Valid Loss: 1.82  Valid Acc: 0.5340 Valid Pre: 0.5274  Valid Recall: 0.4887 Valid F1: 0.5073  Valid Roc: 0.5688\n",
            "alpha =  tensor([[0.2160],\n",
            "        [0.3815],\n",
            "        [0.5594]], grad_fn=<SigmoidBackward0>)\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ -67.5245, -471.6819,  402.2168,   84.6071,  175.7833,  420.1417,\n",
            "         124.5433, -216.7776, -349.7478, -413.7000,  895.3337,  269.5316],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "alpha =  tensor([[0.2151],\n",
            "        [0.3800],\n",
            "        [0.5578]])\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ 0.0454,  0.0484,  0.0342, -0.0245,  0.0007, -0.0221,  0.0565,  0.0019,\n",
            "        -0.0294,  0.0205,  0.0208,  0.0422])\n",
            "Epoch: 7 (1.7s)  LR: 0.00578 Train Loss: 2.25  Valid Loss: 2.12  Valid Acc: 0.5381 Valid Pre: 0.5188  Valid Recall: 0.8192 Valid F1: 0.6353  Valid Roc: 0.4954\n",
            "alpha =  tensor([[0.2151],\n",
            "        [0.3800],\n",
            "        [0.5578]], grad_fn=<SigmoidBackward0>)\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ -43.2603, -459.1377,  396.3979,   54.5107,  106.7370,  432.9451,\n",
            "         123.7375, -210.6291, -367.3983, -456.0482,  785.8967,  290.0295],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "alpha =  tensor([[0.2143],\n",
            "        [0.3788],\n",
            "        [0.5566]])\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ 0.0474,  0.0487,  0.0341, -0.0229,  0.0011, -0.0230,  0.0569,  0.0014,\n",
            "        -0.0275,  0.0196,  0.0219,  0.0421])\n",
            "Epoch: 8 (1.7s)  LR: 0.00500 Train Loss: 3.95  Valid Loss: 2.41  Valid Acc: 0.4882 Valid Pre: 0.4883  Valid Recall: 0.8842 Valid F1: 0.6291  Valid Roc: 0.4082\n",
            "alpha =  tensor([[0.2143],\n",
            "        [0.3788],\n",
            "        [0.5566]], grad_fn=<SigmoidBackward0>)\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ -28.4546, -416.5578,  410.9481,   35.1883,   83.9518,  410.1956,\n",
            "         137.4262, -203.3938, -356.3209, -499.0306,  715.3175,  325.2724],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "alpha =  tensor([[0.2137],\n",
            "        [0.3778],\n",
            "        [0.5556]])\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ 0.0487,  0.0469,  0.0335, -0.0223, -0.0002, -0.0224,  0.0570,  0.0016,\n",
            "        -0.0285,  0.0200,  0.0220,  0.0415])\n",
            "Epoch: 9 (1.6s)  LR: 0.00422 Train Loss: 3.89  Valid Loss: 2.36  Valid Acc: 0.4827 Valid Pre: 0.4816  Valid Recall: 0.7006 Valid F1: 0.5708  Valid Roc: 0.4194\n",
            "alpha =  tensor([[0.2137],\n",
            "        [0.3778],\n",
            "        [0.5556]])\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ 0.0487,  0.0469,  0.0335, -0.0223, -0.0002, -0.0224,  0.0570,  0.0016,\n",
            "        -0.0285,  0.0200,  0.0220,  0.0415])\n",
            "Last Test Acc: 0.6293 Last Test Pre: 0.7222 Last Test Recall: 0.6950 Last Test F1: 0.7083 Last Test ROC: 0.5875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation or Testing"
      ],
      "metadata": {
        "id": "38FJQiUrJ3vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    best_model = torch.load('/content/drive/MyDrive/GNN/%s.pkl'%(args.conv_name))\n",
        "    best_model.eval()\n",
        "    gnn, classifier = best_model\n",
        "    with torch.no_grad():\n",
        "\n",
        "        company_emb=gnn.forward(test_risk_data,test_company_attr,test_hete_graph,test_hyp,test_idx,x_test)\n",
        "\n",
        "        res = classifier.forward(company_emb)\n",
        "\n",
        "        pred=res.argmax(dim=1)\n",
        "        ac=acc(test_label,pred)\n",
        "        pr=pre(test_label,pred)\n",
        "        re=rec(test_label,pred)\n",
        "        f=f1(test_label,pred)\n",
        "        rc=roc(test_label,res[:,1])\n",
        "\n",
        "        print('Best Test Acc: %.4f Best Test Pre: %.4f Best Test Recall: %.4f Best Test F1: %.4f Best Test ROC: %.4f' % (ac,pr,re,f,rc))\n",
        "        print(sum(pred))\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "Y0ZE7HPrJ3C3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94977d29-b5d5-4525-fb57-51906c517b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha =  tensor([[0.2223],\n",
            "        [0.3909],\n",
            "        [0.5692]])\n",
            "Outlist len =  3\n",
            "Outlist 0 len =  3976\n",
            "Outlist 0 1 len =  12\n",
            "Outlist 1 len =  3976\n",
            "Outlist 2 len =  3976\n",
            "res len =  3976\n",
            "res 0 len = 12\n",
            "res 5 len = 12\n",
            "res 10 len = 12\n",
            "res 0 =  tensor([ 0.0285,  0.0410,  0.0364, -0.0422, -0.0018, -0.0100,  0.0471,  0.0042,\n",
            "        -0.0430,  0.0321,  0.0176,  0.0412])\n",
            "Best Test Acc: 0.5845 Best Test Pre: 0.6887 Best Test Recall: 0.6541 Best Test F1: 0.6710 Best Test ROC: 0.5449\n",
            "tensor(302)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GeYclez3M0cs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}